{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d932ea4",
   "metadata": {},
   "source": [
    "# Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb39430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import copy \n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from Q_learning import *\n",
    "import yfinance as yf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb4c9a",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3eea57",
   "metadata": {},
   "source": [
    "Load Data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "AAPL_data = yf.download(\"AAPL\", start=\"2010-01-02\", end=\"2021-01-01\")\n",
    "# MSFT_data = yf.download(\"MSFT\", start=\"2010-01-02\", end=\"2021-01-01\")\n",
    "# GOOGL_data = yf.download(\"GOOGL\", start=\"2010-01-02\", end=\"2021-01-01\")\n",
    "# EBAY_data = yf.download(\"EBAY\", start=\"2010-01-02\", end=\"2021-01-01\")\n",
    "# AMZN_data = yf.download(\"AMZN\", start=\"2010-01-02\", end=\"2021-01-01\")\n",
    "\n",
    "AAPL_returns = np.sign(np.diff(AAPL_data[\"Close\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600a871",
   "metadata": {},
   "source": [
    "We map the returns to [-2,-1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e14c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_return = 0.01\n",
    "ind_0_pos = (np.abs(np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])<small_return)&((np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])>=0)\n",
    "ind_pos = ((np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])>=small_return)\n",
    "ind_0_neg = (np.abs(np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])<small_return)&((np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])<0)\n",
    "ind_neg = ((np.diff(AAPL_data[\"Close\"])/(AAPL_data[\"Close\"])[:-1])<= - small_return)\n",
    "AAPL_returns = np.zeros(len(AAPL_data)-1)\n",
    "AAPL_returns[ind_0_pos] = 1\n",
    "AAPL_returns[ind_pos] = 2\n",
    "AAPL_returns[ind_0_neg] = -1\n",
    "AAPL_returns[ind_neg] = -2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2764b0",
   "metadata": {},
   "source": [
    "We define the training and the  testing period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d2aeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end = 2200\n",
    "AAPL_returns_train = AAPL_returns[:2200]\n",
    "\n",
    "#Testing Period 1\n",
    "test_period_1_start = 2201\n",
    "test_period_1_end = 2301\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AAPL_returns_test1 = AAPL_returns[test_period_1_start:test_period_1_end]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4b7d7",
   "metadata": {},
   "source": [
    "# Setting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578cc81d",
   "metadata": {},
   "source": [
    "Fix the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9d7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 5 # Length of history\n",
    "returns = AAPL_returns_train\n",
    "\n",
    "# State Space\n",
    "T = [-2,-1,1,2]\n",
    "X = np.array(list(itertools.product(T, repeat=h)))\n",
    "# Action Space\n",
    "A = np.array(T)\n",
    "\n",
    "def c(x,y):\n",
    "    return 100*np.linalg.norm(x[:-1]-y[:-1])+np.abs(x[-1]-y[-1])\n",
    "\n",
    "def r(x,a,y):\n",
    "    return int(y[-1]==a)\n",
    "epsilon = 0.1 # Radius of the Wasserstein Ball\n",
    "alpha = 0.45 # Discount Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c301f2e",
   "metadata": {},
   "source": [
    "To speed up the computations we compute the Values p_u, p_d, p_u0, p_d0 in dependence of each state once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1287e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = []\n",
    "for x in X:\n",
    "    eps = 1e-8\n",
    "    x_u = np.concatenate([x[1:],[2]])\n",
    "    x_d = np.concatenate([x[1:],[-2]])\n",
    "    x_u0 = np.concatenate([x[1:],[1]])\n",
    "    x_d0 = np.concatenate([x[1:],[-1]])    \n",
    "    p_u_raw = np.sum([np.all(returns[i:(h+i)]==x_u) for i in range(len(returns)-h-1)])\n",
    "    p_d_raw = np.sum([np.all(returns[i:(h+i)]==x_d) for i in range(len(returns)-h-1)])\n",
    "    p_u0_raw = np.sum([np.all(returns[i:(h+i)]==x_u0) for i in range(len(returns)-h-1)])\n",
    "    p_d0_raw = np.sum([np.all(returns[i:(h+i)]==x_d0) for i in range(len(returns)-h-1)])\n",
    "    p_u = (eps/4+p_u_raw)/(p_u_raw+p_d_raw+p_u0_raw+p_d0_raw+eps)\n",
    "    p_d = (eps/4+p_d_raw)/(p_u_raw+p_d_raw+p_u0_raw+p_d0_raw+eps)\n",
    "    p_u0= (eps/4+p_u0_raw)/(p_u_raw+p_d_raw+p_u0_raw+p_d0_raw+eps)\n",
    "    p_d0= (eps/4+p_d0_raw)/(p_u_raw+p_d_raw+p_u0_raw+p_d0_raw+eps)\n",
    "    p_list.append([p_u,p_d,p_u0,p_d0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84bd67",
   "metadata": {},
   "source": [
    "Define density and a \"prediction\" of the next state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b31c9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_0(k,x,a):\n",
    "    ind = np.flatnonzero((x_0==X).all(1))[0]\n",
    "    p_u,p_d,p_u0,p_d0 = p_list[ind]\n",
    "    return p_d*np.all(k==np.concatenate([x[1:],[-2]]))+p_d0*np.all(k==np.concatenate([x[1:],[-1]]))+ p_u0*np.all(k==np.concatenate([x[1:],[1]]))+ p_u*np.all(k==np.concatenate([x[1:],[2]]))\n",
    "def P_0(x,a):\n",
    "    ind = np.flatnonzero((x_0==X).all(1))[0]\n",
    "    p_u,p_d,p_u0,p_d0 = p_list[ind]\n",
    "    rand_unif=(np.random.random_sample(size=1))\n",
    "    rand = -2*int(rand_unif<p_d)-1*int((rand_unif>(p_d))*(rand_unif<(p_d+p_d0)))+1*int((rand_unif>(p_d+p_d0))*(rand_unif<(p_d+p_d0+p_u0)))+2*int(rand_unif>(p_d+p_d0+p_u0))\n",
    "    return np.concatenate([x[1:],[rand]])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9549d9",
   "metadata": {},
   "source": [
    "Determine the initial value (randomly chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22bc5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "x_0 = rng.choice(np.array([returns[i:(h+i)]  for i in range(len(returns)-h-1)]),axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2adef5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44dc67",
   "metadata": {},
   "source": [
    "Train the policies by Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ade857",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:09<00:00, 5318.76it/s]\n"
     ]
    }
   ],
   "source": [
    "Q_opt_nonrobust = q_learning(X,\n",
    "               A,\n",
    "               r,\n",
    "               P_0, # Simulation of next state in dependence of x and a\n",
    "               alpha,\n",
    "               x_0, \n",
    "               eps_greedy = 0.1,\n",
    "               Nr_iter = 50000,\n",
    "               gamma_t_tilde = lambda t: 1/(t+1),\n",
    "               Q_0 = 2*np.ones([len(X),len(A)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f0f8387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [10:27:33<00:00,  1.33it/s]   \n"
     ]
    }
   ],
   "source": [
    "Q_opt_robust = robust_q_learning(X,\n",
    "               A,\n",
    "               r,\n",
    "               c,\n",
    "               P_0, # Simulation of next state in dependence of x and a\n",
    "               p_0, # The probability mass function\n",
    "               epsilon,\n",
    "               alpha,\n",
    "               x_0, \n",
    "               eps_greedy = 0.1,\n",
    "               Nr_iter = 50000,\n",
    "               q =1,\n",
    "               gamma_t_tilde =  lambda t: 1/(t+1),\n",
    "               time_series = True,\n",
    "               T=T,\n",
    "               Q_0 = 2*np.ones([len(X),len(A)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0e103",
   "metadata": {},
   "source": [
    " Derive the optimal strategies from the optimal Q value functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8a674fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.ndim(A)>1:\n",
    "    A_list = A\n",
    "else:\n",
    "    A_list = np.array([[a] for a in A])\n",
    "if np.ndim(X)>1:\n",
    "    X_list = X\n",
    "else:\n",
    "    X_list = np.array([[x] for x in X])\n",
    "def a_index(a):\n",
    "    return np.flatnonzero((a==A_list).all(1))[0]\n",
    "def x_index(x):\n",
    "    return np.flatnonzero((x==X_list).all(1))[0]\n",
    "def a_opt_robust(x):\n",
    "    return A[np.argmax(Q_opt_robust[x_index(x),:])]\n",
    "def a_opt_nonrobust(x):\n",
    "    return A[np.argmax(Q_opt_nonrobust[x_index(x),:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143803c0",
   "metadata": {},
   "source": [
    "Compare with trivial strategy (constant with highest success ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1143adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_trivial(x):\n",
    "    m = np.max([np.sum(AAPL_returns ==-2 ),np.sum(AAPL_returns ==-1 ),np.sum(AAPL_returns == 1),np.sum(AAPL_returns == 2)])\n",
    "    return int(np.sum(AAPL_returns == 1)==m)-int(np.sum(AAPL_returns == -1)==m)+2*int(np.sum(AAPL_returns == 2)==m)-2*int(np.sum(AAPL_returns == -2)==m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f79fa",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca60536",
   "metadata": {},
   "source": [
    "### Training Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e58e28",
   "metadata": {},
   "source": [
    "Test on training period (to see whether strategy was properly trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6340a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Training Period:\n",
      "\n",
      "Days:             2200\n",
      "Negative Returns:   404\n",
      "Small Neg. Returns: 637\n",
      "Small Pos. Returns: 627\n",
      "Positive Returns:   532\n",
      "Non-Robust:       28.7147% correct \n",
      "Robust:           22.3336% correct\n",
      "Trivial:          28.9426% correct  \n"
     ]
    }
   ],
   "source": [
    "test_returns0 = AAPL_returns_train\n",
    "X_t = np.array([test_returns0[i:(h+i)]  for i in range(len(test_returns0)-h-1)])\n",
    "print(\"Test on Training Period:\\n\\nDays:             {}\\nNegative Returns:   {}\\nSmall Neg. Returns: {}\\nSmall Pos. Returns: {}\\nPositive Returns:   {}\".format(len(test_returns0),\n",
    "                                                                            np.sum(test_returns0==-2),\n",
    "                                                                            np.sum(test_returns0==-1),                                             \n",
    "                                                                            np.sum(test_returns0==1),\n",
    "                                                                            np.sum(test_returns0==2)))\n",
    "non_robust_rewards = np.array([r(X_t[i],a_opt_nonrobust(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "robust_rewards = np.array([r(X_t[i],a_opt_robust(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "trivial_rewards = np.array([r(X_t[i],a_trivial(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "print(\"Non-Robust:       {0:0.4f}% correct \\nRobust:           {1:0.4f}% correct\\nTrivial:          {2:0.4f}% correct  \".format(100*np.sum(non_robust_rewards>0)/len(X_t),\n",
    "                                                                          100*np.sum(robust_rewards>0)/len(X_t),\n",
    "                                                                                     100*np.sum(trivial_rewards>0)/len(X_t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc11fab",
   "metadata": {},
   "source": [
    "### Test Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bb0402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Period 1:\n",
      "\n",
      "Days:             100\n",
      "Negative Returns:   29\n",
      "Small Neg. Returns: 21\n",
      "Small Pos. Returns: 22\n",
      "Positive Returns:   28\n",
      "Non-Robust:       23.4043% correct \n",
      "Robust:           28.7234% correct\n",
      "Trivial:          21.2766% correct  \n"
     ]
    }
   ],
   "source": [
    "test_returns1 = AAPL_returns_test1\n",
    "X_t = np.array([test_returns1[i:(h+i)]  for i in range(len(test_returns1)-h-1)])\n",
    "print(\"Test Period 1:\\n\\nDays:             {}\\nNegative Returns:   {}\\nSmall Neg. Returns: {}\\nSmall Pos. Returns: {}\\nPositive Returns:   {}\".format(len(test_returns1),\n",
    "                                                                            np.sum(test_returns1==-2),\n",
    "                                                                            np.sum(test_returns1==-1),                                             \n",
    "                                                                            np.sum(test_returns1==1),\n",
    "                                                                            np.sum(test_returns1==2)))\n",
    "non_robust_rewards = np.array([r(X_t[i],a_opt_nonrobust(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "robust_rewards = np.array([r(X_t[i],a_opt_robust(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "trivial_rewards = np.array([r(X_t[i],a_trivial(X_t[i]),X_t[i+1]) for i in range(len(X_t)-1)])\n",
    "print(\"Non-Robust:       {0:0.4f}% correct \\nRobust:           {1:0.4f}% correct\\nTrivial:          {2:0.4f}% correct  \".format(100*np.sum(non_robust_rewards>0)/len(X_t),\n",
    "                                                                          100*np.sum(robust_rewards>0)/len(X_t),\n",
    "                                                                                     100*np.sum(trivial_rewards>0)/len(X_t)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
